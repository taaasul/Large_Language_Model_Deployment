# 人工智能导论第四次课程作业 - 大语言模型部署

## 作业概述

本项目为人工智能导论课程第四次作业，通过在魔搭平台上部署并测试大语言模型，探索不同模型在中文语义理解任务中的表现差异。作业包括模型部署、问答测试和横向对比分析三个核心环节。

## 实验环境

- **平台**: 魔搭社区 GPU Notebook
- **硬件配置**: 8vCPU 32GB RAM + NVIDIA GPU (24GB VRAM)
- **系统镜像**: Ubuntu 22.04 + CUDA 12.1.0 + Python 3.11
- **核心依赖**: 
  - Python 3.10
  - PyTorch 2.3.0+cu118
  - Transformers 4.33.3
  - bitsandbytes 0.43

## 部署模型

成功部署了三个开源大语言模型：

1. **Qwen-7B-Chat** - 阿里巴巴通义千问7B参数对话模型
2. **ChatGLM3-6B** - 智谱AI第三代6B参数对话模型
3. **Baichuan2-7B-Chat** - 百川智能7B参数对话模型

## 测试内容

设计了五个中文语义理解测试案例：

1. **语义歧义测试**: 冬天/夏天"能穿多少穿多少"的不同含义
2. **逻辑推理测试**: "单身狗产生的原因"重复表述的深层含义
3. **指代消解测试**: 复杂嵌套代词"他知道我知道你知道他不知道"
4. **语义解析测试**: 人名谐音句"明明明明明白白白喜欢他"
5. **多义词理解**: 对话中"意思"一词的多种语境含义

## 主要发现

**性能对比**:
- **Qwen-7B-Chat**: 长文本理解和逻辑推理能力突出，适合文档分析类任务
- **ChatGLM3-6B**: 对话交互自然流畅，多轮对话体验佳，适合客服机器人
- **Baichuan2-7B-Chat**: 数值计算和结构化输出优秀，适合代码生成和数学解题

**技术特点**:
- **架构差异**: 分别采用GQA机制、GLM双向注意力、RoPE位置编码
- **显存效率**: ChatGLM3-6B体积最小，Qwen-7B-Chat长文本显存效率高
- **算法创新**: RLAIF对齐、多阶段训练、动态批处理等不同优化策略

## 目录结构
├── README.md # 项目说明文档
├── report/ # 作业报告
│ └── hw4_2351273_邓语乐.pdf
└── screenshots/ # 测试截图
├── qianwen/ # Qwen-7B-Chat测试截图
│ ├── deployment.png # 部署完成截图
│ ├── test1.png # 测试问题1截图
│ ├── test2.png # 测试问题2截图
│ ├── test3.png # 测试问题3截图
│ ├── test4.png # 测试问题4截图
│ └── test5.png # 测试问题5截图
├── chatglm/ # ChatGLM3-6B测试截图
│ ├── deployment.png # 部署完成截图
│ ├── test1.png # 测试问题1截图
│ ├── test2.png # 测试问题2截图
│ ├── test3.png # 测试问题3截图
│ ├── test4.png # 测试问题4截图
│ └── test5.png # 测试问题5截图
└── baichuan/ # Baichuan2-7B-Chat测试截图
├── deployment.png # 部署完成截图
├── test1.png # 测试问题1截图
├── test2.png # 测试问题2截图
├── test3.png # 测试问题3截图
├── test4.png # 测试问题4截图
└── test5.png # 测试问题5截图

## 学生信息

- **姓名**: 邓语乐
- **学号**: 2351273
- **课程**: 人工智能导论
- **作业**: 第四次课程作业 - 大语言模型部署
